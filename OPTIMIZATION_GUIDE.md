# RAG系统优化指南

## 问题诊断

根据您提供的测试结果，系统存在以下主要问题：

### 1. 检索召回率不足
- **症状**：多个问题的答案明明在文档中，但系统回答"我不知道"
- **原因**：
  - 检索文档数（k=5）太少
  - chunk_size=1000可能导致关键信息被截断
  - 嵌入模型对中文技术文档的理解能力不足

### 2. 答案生成质量不佳
- **症状**：即使检索到相关内容，答案仍不够精确
- **原因**：
  - Prompt模板过于简单，缺乏明确指引
  - LLM没有充分利用检索到的信息

### 3. 专业术语匹配困难
- **症状**：涉及标准编号、系统名称等专业术语的问题表现不佳
- **原因**：
  - 纯语义检索对精确匹配支持不足
  - 缺少关键词匹配机制

## 已实施的优化

### ✅ 优化0A：增强版检索器 - 修复重复和不相关问题（新增 retrieval_enhanced.py）

**问题诊断**：
1. **检索完全不相关**：问"株洲中车中标金额"返回欧洲铁路局英文内容
2. **结果高度重复**：10个检索结果几乎完全相同（同一段重复出现）
3. **关键词匹配失效**：专有名词如"株洲中车"、"南京地铁S7"完全没有匹配

**根本原因**：
1. 原检索器使用`id(doc)`（对象内存地址）进行去重，导致相同内容的不同对象无法去重
2. `chunk_overlap=300`过大，导致大量重复chunk被索引
3. 中文专有名词提取不准确，关键词搜索效果差
4. 没有多样性约束，相似文档被重复返回

**解决方案**（retrieval_enhanced.py）：

1. **基于内容的去重**：使用MD5哈希对文档内容去重（前200字符）

2. **改进的中文关键词提取**：
   - 提取中文专有名词（连续2+个汉字）
   - 提取数字（年份、金额、百分比）
   - 提取特殊标识符（如GB/T 43267、S7）

3. **多样性约束**：避免返回相似度>90%的文档（使用Jaccard相似度）

4. **增强的关键词评分**：
   - 完整查询匹配：+10分
   - 专有名词/数字匹配：额外+2分
   - 高频关键词：使用log尺度避免过度偏向

5. **减少chunk重叠**（config.py）：`chunk_overlap: 300 → 150`

**效果预期**：
- ✅ 消除重复结果：10个结果来自不同文档位置
- ✅ 提高相关性：专有名词精确匹配
- ✅ 多语言支持：中英文、数字、特殊标识符都能准确提取
- ✅ 内容多样性：避免相似内容重复出现

**使用方法**：系统自动使用（当ADVANCED_FEATURES启用时）

**技术细节**：
- 候选数量：k*3（增加候选池以应对去重损失）
- 去重阈值：基于前200字符的MD5哈希
- 多样性阈值：Jaccard相似度<90%
- 关键词权重：高分关键词(>0.7)获得70%权重，否则30%

---

### ✅ 优化0：清理LLM输出（已修改 config.py 和 rag_system.py）

**问题**：使用DeepSeek-R1等推理模型时，输出包含大量思考过程，导致答案冗余

**解决方案**：
1. **修改提示词模板**（config.py:121）：
   - 添加第7条指示："请直接输出最终答案，不要展示思考过程、推理步骤或任何中间分析。不要使用<think>标签。"
   - 修改提示词结尾："请直接提供准确答案（不要包含思考过程）"

2. **添加答案后处理**（rag_system.py:414-456）：
   - 新增`_clean_answer()`方法
   - 移除`<think>...</think>`标签及其内容
   - 移除常见思考过程标记（"好的，我现在需要..."、"让我分析..."等）
   - 清理多余空行

**效果预期**：
- 答案更简洁、直接
- 去除所有冗余的思考过程
- 仅保留实质性回答内容

**使用方法**：
```bash
# 无需额外操作，系统自动应用
python main.py
```

### ✅ 优化1：改进嵌入模型（已修改 config.py）

```python
EMBEDDING_CONFIG = {
    "model_name": "BAAI/bge-m3",  # 多语言模型，支持中英德等100+语言
}
```

**效果预期**：
- 中文文档理解能力提升30-50%
- 专业术语检索准确率提高

**使用方法**：
```bash
# 安装新模型（首次使用需要下载）
pip install -U sentence-transformers

# 重新构建向量库
python main.py
# 选择 N（不使用已有向量库）
```

### ✅ 优化2：增加检索文档数量（已修改 config.py）

```python
RETRIEVAL = {
    "k": 10,  # 从5增加到10
}
```

**效果预期**：
- 召回率提升，减少"我不知道"的情况
- 可能包含更多相关上下文

### ✅ 优化3：优化文本分割策略（已修改 config.py）

```python
TEXT_SPLITTING = {
    "chunk_size": 1500,  # 从1000增加到1500
    "chunk_overlap": 300,  # 从200增加到300
}
```

**效果预期**：
- 表格、列表等结构化信息更完整
- 上下文连贯性更好

### ✅ 优化4：改进Prompt模板（已修改 config.py）

新的Prompt包含：
- 明确的角色定位（铁路交通领域专家）
- 6条详细指示
- 强调精确数据的重要性

**效果预期**：
- 答案准确性提高
- 减少幻觉和推测
- 对数字、日期等敏感信息更谨慎

### ✅ 优化5：集成混合检索和重排序（已实施）

**已启用功能**：
```python
ADVANCED_FEATURES = {
    "hybrid_search": True,  # 混合搜索（关键词+语义）
    "hybrid_weight": 0.3,  # 关键词权重30%
    "reranking": True,  # 重排序
    "reranking_top_k": 20,  # 先检索20个再重排到10个
}
```

**实现文件**：
- `rag_enhanced.py` - 增强检索器实现
- `rag_system.py` - 自动集成增强检索器

**工作原理**：
1. **混合检索**：
   - 70%语义相似度 + 30%关键词匹配
   - 特别适合标准编号、专业术语查询
   - 提升精确匹配能力

2. **重排序**：
   - 先检索20个候选文档
   - 基于关键词重叠重新排序
   - 返回最相关的10个

**效果预期**：
- 标准编号、专业术语匹配准确率：+40-60%
- 综合检索准确率：+20-30%
- 对问题1、2、5、9、10等精确查询特别有效

## 可选的进阶优化

### 方案A：使用BM25算法（已有简化版，可选升级）

**当前状态**：
- ✅ 已实施简化版关键词匹配
- 📋 可选：升级到完整BM25算法

**升级步骤**（可选）：

1. 安装依赖：
```bash
pip install rank-bm25 jieba
```

2. 修改 `rag_enhanced.py`，将 `_keyword_match` 方法替换为BM25实现：

```python
from rank_bm25 import BM25Okapi
import jieba  # 中文分词

def _keyword_match_bm25(self, query: str, k: int) -> List[tuple]:
    """使用BM25算法的关键词匹配"""
    # 分词
    tokenized_corpus = [list(jieba.cut(doc.page_content)) for doc in self.documents]
    bm25 = BM25Okapi(tokenized_corpus)

    # 查询
    tokenized_query = list(jieba.cut(query))
    scores = bm25.get_scores(tokenized_query)

    # 返回top-k
    top_indices = scores.argsort()[-k:][::-1]
    return [(self.documents[i], scores[i]) for i in top_indices]
```

**预期提升**：
- 关键词匹配精度：+10-15%（相对当前简化版）
- 更适合长文档检索

### 方案B：使用神经网络重排序模型（已有简化版，可选升级）

**当前状态**：
- ✅ 已实施基于关键词的简单重排序
- 📋 可选：升级到神经网络重排序模型

**升级步骤**（可选）：

1. 安装重排序模型：
```bash
pip install sentence-transformers
```

2. 修改 `rag_enhanced.py`，添加神经网络重排序：

```python
from sentence_transformers import CrossEncoder

class EnhancedRetriever:
    def __init__(self, ...):
        # 初始化重排序模型
        self.reranker = CrossEncoder('BAAI/bge-reranker-base')

    def _simple_rerank(self, query: str, docs: List[Document], top_k: int):
        """使用神经网络重排序"""
        # 构造输入对
        pairs = [[query, doc.page_content[:512]] for doc in docs]

        # 预测相关性分数
        scores = self.reranker.predict(pairs)

        # 排序并返回
        scored = list(zip(docs, scores))
        scored.sort(key=lambda x: x[1], reverse=True)
        return [doc for doc, _ in scored[:top_k]]
```

**预期提升**：
- 重排序精度：+15-25%（相对当前简化版）
- 需要额外内存：~500MB
- 增加响应时间：~1-2秒

### 方案C：查询改写（Query Rewriting）

针对复杂问题，先让LLM改写查询：

```python
def rewrite_query(self, question: str) -> str:
    """使用LLM改写查询，提取关键信息"""
    prompt = f"""
    将以下问题改写为更适合检索的关键词查询，保留所有专业术语、数字、日期等关键信息：

    原问题：{question}

    改写后的查询：
    """
    rewritten = self.llm.predict(prompt)
    return rewritten
```

### 方案D：多查询检索

对一个问题生成多个不同角度的查询：

```python
def multi_query_retrieval(self, question: str):
    # 1. 生成多个查询变体
    queries = [
        question,
        f"关于{提取主题(question)}的详细信息",
        f"{提取关键词(question)}的数据统计",
    ]

    # 2. 对每个查询检索
    all_docs = []
    for q in queries:
        docs = self.vectorstore.similarity_search(q, k=5)
        all_docs.extend(docs)

    # 3. 去重并重排序
    unique_docs = 去重(all_docs)
    return unique_docs[:10]
```

## 针对具体问题的优化建议

### 问题1：株洲中车中标金额
**问题类型**：精确数据查询
**优化方案**：
- 使用混合检索（BM25 + 语义）
- 增加chunk_size到2000（表格可能很长）
- 查询改写："株洲中车时代电气 2024 中标 金额"

### 问题2、3：百分比、增长数据
**问题类型**：文档内精确数值
**优化方案**：
- 关键词增强："知识图谱迁移 2025 百分比"
- 使用重排序，优先返回包含数字的段落
- 后处理：从检索结果中提取数字

### 问题5：事件时间查询
**问题类型**：时间序列信息
**优化方案**：
- 增加时间戳提取
- 多跳推理：先找事件，再找时间
- 检索时优先包含"时间"、"日期"的段落

### 问题7：标准条款
**问题类型**：结构化信息
**优化方案**：
- 保持更大的chunk（2000+）
- 专门处理"第X层"、"要素"等结构化描述
- 考虑使用表格解析

### 问题9：测试需求编号
**问题类型**：编号查询
**优化方案**：
- 正则表达式增强："T[0-9]+"模式匹配
- 关键词必须包含"测试需求"
- BM25权重提高

## 性能对比测试

优化前后对比（预期）：

| 指标 | 优化前 | 优化后（基础） | 优化后（高级） |
|------|--------|--------------|--------------|
| 召回率 | 40% | 65% | 85% |
| 准确率 | 50% | 70% | 90% |
| "不知道"率 | 40% | 20% | 5% |
| 平均响应时间 | 8s | 10s | 15s |

## 实施建议

### 阶段1：立即实施（已完成）
- ✅ 修改config.py中的配置
- ✅ 更新Prompt模板
- ⏳ 重新构建向量库

### 阶段2：短期优化（1-2天）
- 实施混合检索（BM25）
- 添加查询改写
- 针对特定问题类型优化

### 阶段3：长期优化（1周）
- 集成重排序模型
- 实现多查询检索
- 添加后处理规则（数字提取、时间解析等）
- 构建评估数据集

## 监控和调优

### 关键指标
1. **召回率**：答案所在文档是否被检索到
2. **MRR（Mean Reciprocal Rank）**：正确文档的平均排名
3. **答案准确率**：最终答案是否正确

### 调优技巧
1. 如果召回率低：增加k，优化查询
2. 如果准确率低但召回率高：优化Prompt，添加重排序
3. 如果响应慢：减少k，使用更小的模型

## 快速测试

重新运行测试：

```bash
# 1. 重新构建向量库（使用新配置）
python main.py
# 输入: N

# 2. 查看改进效果
# 对比之前的输出，特别关注：
# - "我不知道"的减少
# - 数字、日期等精确信息的准确性
# - 检索到的文档相关性
```

## 下一步行动

1. **立即执行**：
   ```bash
   # 重新构建向量库
   python main.py
   ```

2. **评估效果**：
   - 对比10个测试问题的答案质量
   - 记录改进的问题数量

3. **进一步优化**：
   - 如果效果显著：继续使用当前配置
   - 如果仍有问题：实施方案A（混合检索）

4. **持续改进**：
   - 收集更多失败案例
   - 针对性优化
   - 建立评估数据集

---

**注意事项**：
- 更换嵌入模型后必须重新构建向量库
- chunk_size增大会增加内存占用
- k值增大会略微降低响应速度但提升准确率
- 建议在GPU环境下运行以加速嵌入过程
